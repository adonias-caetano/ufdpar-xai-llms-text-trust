{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d32faf66",
   "metadata": {},
   "source": [
    "*Library and Installation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba06ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install unsloth\n",
    "%pip install --upgrade --force-reinstall --no-cache-dir unsloth unsloth_zoo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73422c8e",
   "metadata": {},
   "source": [
    "*Initial Structure*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee3807fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-20 14:24:59.695236: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-10-20 14:24:59.703955: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1760970299.713520 4052463 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1760970299.716764 4052463 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1760970299.724864 4052463 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1760970299.724873 4052463 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1760970299.724874 4052463 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1760970299.724875 4052463 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-10-20 14:24:59.727517: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 10-20 14:25:01 [__init__.py:216] Automatically detected platform cuda.\n",
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    }
   ],
   "source": [
    "from unsloth import tokenizer_utils\n",
    "def do_nothing(*args, **kwargs):\n",
    "    pass\n",
    "tokenizer_utils.fix_untrained_tokens = do_nothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ebd0ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Major: 8, Minor: 9\n",
      "==((====))==  Unsloth 2025.10.1: Fast Qwen3 patching. Transformers: 4.56.2. vLLM: 0.10.2.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 4090. Num GPUs = 2. Max memory: 23.643 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.8.0+cu128. CUDA: 8.9. CUDA Toolkit: 12.8. Triton: 3.4.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.32.post2. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b4f813628c34f77b3a45de1bbb30630",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "from typing import Any, Dict, List, Tuple, Union\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from transformers import (\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForLanguageModeling,\n",
    ")\n",
    "\n",
    "from trl import SFTTrainer\n",
    "from unsloth import FastLanguageModel\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# GPU INFORMATION\n",
    "# ---------------------------\n",
    "major_version, minor_version = torch.cuda.get_device_capability()\n",
    "print(f\"Major: {major_version}, Minor: {minor_version}\")\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# MODEL LIST\n",
    "# ---------------------------\n",
    "used_models = [\n",
    "    \"unsloth/Qwen3-0.6B-Base-unsloth-bnb-4bit\",\n",
    "    \"unsloth/Qwen3-1.7B-Base-unsloth-bnb-4bit\",\n",
    "    \"unsloth/Qwen3-4B-Base-unsloth-bnb-4bit\",\n",
    "    \"unsloth/Qwen3-8B-Base-unsloth-bnb-4bit\",\n",
    "    \"unsloth/Qwen3-14B-Base-unsloth-bnb-4bit\",\n",
    "]\n",
    "\n",
    "NUM_CLASSES = 2\n",
    "max_seq_length = 2048\n",
    "dtype = None  # Auto detection\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# MODEL SELECTION\n",
    "# ---------------------------\n",
    "model_name = \"unsloth/Qwen3-14B-Base-unsloth-bnb-4bit\"\n",
    "load_in_4bit = True\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# MODEL LOADING\n",
    "# ---------------------------\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=model_name,\n",
    "    load_in_4bit=load_in_4bit,\n",
    "    max_seq_length=max_seq_length,\n",
    "    dtype=dtype,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7c2559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 5120])\n",
      "torch.Size([151936, 5120])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{15: 0, 16: 1, 17: 2}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_token_ids = []\n",
    "for i in range(0, NUM_CLASSES+1):\n",
    "    number_token_ids.append(tokenizer.encode(str(i), add_special_tokens=False)[0])\n",
    "par = torch.nn.Parameter(model.lm_head.weight[number_token_ids, :])\n",
    "\n",
    "old_shape = model.lm_head.weight.shape\n",
    "old_size = old_shape[0]\n",
    "print(par.shape)\n",
    "print(old_shape)\n",
    "\n",
    "model.lm_head.weight = par\n",
    "\n",
    "reverse_map = {value: idx for idx, value in enumerate(number_token_ids)} # will be used later to convert an idx from the old tokenizer to the new lm_head\n",
    "reverse_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef05c686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Offloading output_embeddings to disk to save VRAM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.10.1 patched 40 layers with 40 QKV layers, 40 O layers and 40 MLP layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Training lm_head in mixed precision to save VRAM\n",
      "trainable parameters: 64240640\n"
     ]
    }
   ],
   "source": [
    "from peft import LoftQConfig\n",
    "\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16,\n",
    "    target_modules = [\n",
    "        \"lm_head\", \n",
    "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "        \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0, \n",
    "    bias = \"none\",    \n",
    "    use_gradient_checkpointing = \"unsloth\",\n",
    "    random_state = 3407,\n",
    "    use_rslora = True,  \n",
    ")\n",
    "print(\"trainable parameters:\", sum(p.numel() for p in model.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9d73fd",
   "metadata": {},
   "source": [
    "*Data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbaf3b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3030\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv(\"/home/joaopedro/joaopedro/llm/Mestrado/Datasets/Boamente_Treino_Atualizado.csv\") #columns are text,label\n",
    "\n",
    "train_df, val_df = train_test_split(data, test_size=0.2, random_state=42)\n",
    "print(len(train_df))\n",
    "\n",
    "token_counts = [len(tokenizer.encode(x)) for x in train_df.text]\n",
    "a = plt.hist(token_counts, bins=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9869bb90",
   "metadata": {},
   "source": [
    "*Prompt and Data Collator*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ca0067",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Aqui estÃ¡ uma sentenÃ§a.\n",
    "{}\n",
    "\n",
    "Se a sentenÃ§a contÃ©m ideaÃ§Ã£o suicida, responda \"Sim\". Caso contrÃ¡rio, responda \"NÃ£o\":\n",
    "\n",
    "A resposta correta Ã©: \"{}\"\"\"\n",
    "\n",
    "positivelabel = \"Sim\" #Yes\n",
    "negativelabel = \"NÃ£o\" #No\n",
    "\n",
    "def formatting_prompts_func(dataset_):\n",
    "    texts = []\n",
    "    for i in range(len(dataset_['text'])):\n",
    "        text_ = dataset_['text'].iloc[i]\n",
    "        label_ = dataset_['label'].iloc[i] #the csv is setup so that the label column corresponds exactly to the 3 classes defined above in the prompt (important)\n",
    "\n",
    "        text = prompt.format(text_, label_)\n",
    "\n",
    "        texts.append(text)\n",
    "    return texts\n",
    "\n",
    "#apply formatting_prompts_func to train_df\n",
    "train_df['text'] = formatting_prompts_func(train_df)\n",
    "train_dataset = datasets.Dataset.from_pandas(train_df,preserve_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cea6e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataCollatorForLastTokenLM(DataCollatorForLanguageModeling):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *args,\n",
    "        mlm: bool = False,\n",
    "        ignore_index: int = -100,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(*args, mlm=mlm, **kwargs)\n",
    "        self.ignore_index = ignore_index\n",
    "\n",
    "    def torch_call(self, examples: List[Union[List[int], Any, Dict[str, Any]]]) -> Dict[str, Any]:\n",
    "        batch = super().torch_call(examples)\n",
    "\n",
    "        for i in range(len(examples)):\n",
    "            last_token_idx = (batch[\"labels\"][i] != self.ignore_index).nonzero()[-1].item()\n",
    "            batch[\"labels\"][i, :last_token_idx] = self.ignore_index\n",
    "            batch[\"labels\"][i, last_token_idx] = reverse_map[ batch[\"labels\"][i, last_token_idx].item() ]\n",
    "        return batch\n",
    "collator = DataCollatorForLastTokenLM(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7857248",
   "metadata": {},
   "source": [
    "*Training with Cross-Validation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89899d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸš€ Iniciando Fold 1/5...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "805679855d2e4d2b911ad84f937747e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unsloth: Tokenizing [\"text\"] (num_proc=36):   0%|          | 0/2424 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ff60c3ca9f0411d8ac943f567dd5f8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unsloth: Tokenizing [\"text\"] (num_proc=36):   0%|          | 0/606 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None}.\n",
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 2,424 | Num Epochs = 1 | Total steps = 38\n",
      "O^O/ \\_/ \\    Batch size per device = 64 | Gradient accumulation steps = 1\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (64 x 1 x 1) = 64\n",
      " \"-____-\"     Trainable parameters = 64,240,640 of 14,054,650,880 (0.46% trained)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 02:35, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.419000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.478200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.592800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.259300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.942700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.504800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.156300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.647900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.799400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.342100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.114700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.249900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.175600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.295100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.320200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.171500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.115800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.144500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.303300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.156000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.209200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.114600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.159500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.218000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.209700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.095500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.148400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.205100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.092500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.243900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.238100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.175300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.149500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.188300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.220300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.082300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.224000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.099800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Resultados do Fold 1: {'eval_loss': 0.1452556848526001, 'eval_runtime': 10.1542, 'eval_samples_per_second': 59.68, 'eval_steps_per_second': 3.742, 'epoch': 1.0}\n",
      "\n",
      "ðŸš€ Iniciando Fold 2/5...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54819d167ee642e19b63f4d934fe9884",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unsloth: Tokenizing [\"text\"] (num_proc=36):   0%|          | 0/2424 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef1e87d4ade94416984eec658bfb331e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unsloth: Tokenizing [\"text\"] (num_proc=36):   0%|          | 0/606 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 2,424 | Num Epochs = 1 | Total steps = 38\n",
      "O^O/ \\_/ \\    Batch size per device = 64 | Gradient accumulation steps = 1\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (64 x 1 x 1) = 64\n",
      " \"-____-\"     Trainable parameters = 64,240,640 of 14,054,650,880 (0.46% trained)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 02:37, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.245900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.030600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.049700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.134600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.088400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.343000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.449200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.220800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.186500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.021100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.132300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.150300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.366600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.327400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.246300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.083700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.142800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.094100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.147500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.126600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.152400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.140300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.114600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.181800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.151600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.169600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.034600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.143900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.065700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.082000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.038500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.208100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.218800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.156400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.048200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.012500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.183300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.053800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Resultados do Fold 2: {'eval_loss': 0.12505994737148285, 'eval_runtime': 9.9383, 'eval_samples_per_second': 60.976, 'eval_steps_per_second': 3.824, 'epoch': 1.0}\n",
      "\n",
      "ðŸš€ Iniciando Fold 3/5...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cdded1931434d3990c3d5113ecff547",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unsloth: Tokenizing [\"text\"] (num_proc=36):   0%|          | 0/2424 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92b80e70344a4446922842d1eac73be5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unsloth: Tokenizing [\"text\"] (num_proc=36):   0%|          | 0/606 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 2,424 | Num Epochs = 1 | Total steps = 38\n",
      "O^O/ \\_/ \\    Batch size per device = 64 | Gradient accumulation steps = 1\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (64 x 1 x 1) = 64\n",
      " \"-____-\"     Trainable parameters = 64,240,640 of 14,054,650,880 (0.46% trained)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 02:37, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.111400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.083300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.157900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.114000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.191500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.103400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.109200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.123500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.033400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.082400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.102900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.061500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.112500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.310300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.231200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.095700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.062800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.051700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.180800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.043900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.036500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.112800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.273700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.195500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.199100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.168900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.005200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.153200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.234800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.529800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.234500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.185500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.285100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.169600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.090400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.044700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.011900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.325000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Resultados do Fold 3: {'eval_loss': 0.08966211974620819, 'eval_runtime': 9.9496, 'eval_samples_per_second': 60.907, 'eval_steps_per_second': 3.819, 'epoch': 1.0}\n",
      "\n",
      "ðŸš€ Iniciando Fold 4/5...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a80dd2af582f4dcc8410fb94201e9fc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unsloth: Tokenizing [\"text\"] (num_proc=36):   0%|          | 0/2424 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d94e04a9558d4a59bb3989b0d067edd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unsloth: Tokenizing [\"text\"] (num_proc=36):   0%|          | 0/606 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 2,424 | Num Epochs = 1 | Total steps = 38\n",
      "O^O/ \\_/ \\    Batch size per device = 64 | Gradient accumulation steps = 1\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (64 x 1 x 1) = 64\n",
      " \"-____-\"     Trainable parameters = 64,240,640 of 14,054,650,880 (0.46% trained)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 02:37, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.192800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.015800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.039800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.027800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.089300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.089700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.128000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.056700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.023300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.088000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.010900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.084300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.032900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.174100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.187000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.032500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.034300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.059500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.070000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.060700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.156600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.146700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.138700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.167700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.153800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.053200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.039400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.032200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.082800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.108600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.043600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.065300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.126200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.095900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.029800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.096300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.051500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Resultados do Fold 4: {'eval_loss': 0.0777270644903183, 'eval_runtime': 9.8821, 'eval_samples_per_second': 61.323, 'eval_steps_per_second': 3.845, 'epoch': 1.0}\n",
      "\n",
      "ðŸš€ Iniciando Fold 5/5...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1171750fd5be47f5a9850ab1ab16a9dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unsloth: Tokenizing [\"text\"] (num_proc=36):   0%|          | 0/2424 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87cc8992a33d410881e7ff42b4a7082d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unsloth: Tokenizing [\"text\"] (num_proc=36):   0%|          | 0/606 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 2,424 | Num Epochs = 1 | Total steps = 38\n",
      "O^O/ \\_/ \\    Batch size per device = 64 | Gradient accumulation steps = 1\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (64 x 1 x 1) = 64\n",
      " \"-____-\"     Trainable parameters = 64,240,640 of 14,054,650,880 (0.46% trained)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 02:36, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.015000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.022800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.083000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.039800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.085100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.063500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.141100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.024900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.084000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.005600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.095600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.411500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.202800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.121500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.216100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.037400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.029900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.024100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.332200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.282700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.084600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.161100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.099600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.153200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.093700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.088300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.059500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.106800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.058900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.081800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.152800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.181800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.085800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.231000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.084800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.062100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.045500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.180500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Resultados do Fold 5: {'eval_loss': 0.09026642888784409, 'eval_runtime': 10.0168, 'eval_samples_per_second': 60.499, 'eval_steps_per_second': 3.794, 'epoch': 1.0}\n",
      "\n",
      "âœ… MÃ©dia final das mÃ©tricas apÃ³s validaÃ§Ã£o cruzada:\n",
      "{'eval_loss': np.float64(0.1055942490696907), 'eval_runtime': np.float64(9.9882), 'eval_samples_per_second': np.float64(60.677), 'eval_steps_per_second': np.float64(3.8048), 'epoch': np.float64(1.0)}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import TrainingArguments\n",
    "from trl import SFTTrainer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from datasets import Dataset\n",
    "\n",
    "#Number of folds for cross-validation\n",
    "num_folds = 5\n",
    "\n",
    "#Convert the pandas dataset to the Hugging Face dataset format (if not already done)\n",
    "full_dataset = Dataset.from_pandas(train_df, preserve_index=False)\n",
    "\n",
    "#Create fold indices for cross-validation\n",
    "skf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=3407)\n",
    "\n",
    "#Store metrics from each fold\n",
    "all_results = []\n",
    "\n",
    "#Iterate over folds\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(full_dataset[\"text\"], full_dataset[\"label\"])):\n",
    "    print(f\"\\nðŸš€ Starting Fold {fold+1}/{num_folds}...\")\n",
    "\n",
    "    #Create training and validation subsets\n",
    "    train_dataset = full_dataset.select(train_idx)\n",
    "    val_dataset = full_dataset.select(val_idx)\n",
    "\n",
    "    #Define training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        per_device_train_batch_size=32,\n",
    "        gradient_accumulation_steps=1,\n",
    "        warmup_steps=10,\n",
    "        learning_rate=1e-4,\n",
    "        fp16=not torch.cuda.is_bf16_supported(),\n",
    "        bf16=torch.cuda.is_bf16_supported(),\n",
    "        logging_steps=1,\n",
    "        optim=\"adamw_8bit\",\n",
    "        weight_decay=0.01,\n",
    "        lr_scheduler_type=\"cosine\",\n",
    "        seed=3407,\n",
    "        output_dir=f\"outputs/fold_{fold+1}\",  #Separate directory for each fold\n",
    "        num_train_epochs=1,\n",
    "        report_to=\"none\",  #Disable logging to external services\n",
    "        group_by_length=True,\n",
    "    )\n",
    "\n",
    "    #Create the Trainer\n",
    "    trainer = SFTTrainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,  #Adding validation\n",
    "        max_seq_length=max_seq_length,\n",
    "        dataset_num_proc=2,\n",
    "        packing=False,\n",
    "        args=training_args,\n",
    "        formatting_func=formatting_prompts_func,\n",
    "        data_collator=collator,\n",
    "    )\n",
    "\n",
    "    #Train the model\n",
    "    trainer.train()\n",
    "\n",
    "    #Evaluate the model on this fold's validation set\n",
    "    metrics = trainer.evaluate()\n",
    "    print(f\"ðŸ“Š Results for Fold {fold+1}: {metrics}\")\n",
    "\n",
    "    # Store the metrics\n",
    "    all_results.append(metrics)\n",
    "\n",
    "#Compute the mean metrics across all folds\n",
    "final_results = {\n",
    "    metric: np.mean([result[metric] for result in all_results]) for metric in all_results[0]\n",
    "}\n",
    "\n",
    "print(\"\\nâœ… Final average metrics after cross-validation:\")\n",
    "print(final_results)\n",
    "\n",
    "#Note: the output is in Portuguese because it was the old version of the code. In the new version, the code and comments are in English."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62915c1c",
   "metadata": {},
   "source": [
    "*Training with 80/20 (Hold-out)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fccdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = train_dataset,\n",
    "    max_seq_length = max_seq_length,\n",
    "    dataset_num_proc = 1,\n",
    "    packing = False, \n",
    "    args = TrainingArguments(\n",
    "        per_device_train_batch_size = 32,\n",
    "        gradient_accumulation_steps = 1,\n",
    "        warmup_steps = 10,\n",
    "        learning_rate = 1e-4,\n",
    "        fp16 = not torch.cuda.is_bf16_supported(),\n",
    "        bf16 = torch.cuda.is_bf16_supported(),\n",
    "        logging_steps = 1,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"cosine\",\n",
    "        seed = 3407,\n",
    "        output_dir = \"outputs\",\n",
    "        num_train_epochs = 1,\n",
    "        report_to = \"none\",\n",
    "        group_by_length = True,\n",
    "    ),\n",
    "    data_collator=collator,\n",
    "    dataset_text_field=\"text\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafeffd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872c0cba",
   "metadata": {},
   "source": [
    "*Inference*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead285d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "FastLanguageModel.for_inference(model) \n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1a1b4c",
   "metadata": {},
   "source": [
    "*Evaluation with metrics*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5179be8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:13<00:00,  6.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Threshold: 0.5622\n",
      "\n",
      "Metrics saved to: /home/joaopedro/joaopedro/llm/roc/metrics_Qwen3_14B.txt\n",
      "\n",
      "Confusion Matrix:\n",
      "[[516  25]\n",
      " [ 15 202]]\n",
      "\n",
      "Evaluation Metrics:\n",
      "Accuracy: 0.9472\n",
      "Precision: 0.8899\n",
      "Recall: 0.9309\n",
      "F1-Score: 0.9099\n",
      "AUC: 0.9804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
    "\n",
    "#Define output directory\n",
    "output_dir = \"/home/joaopedro/joaopedro/llm/roc\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "#Load validation data\n",
    "val_texts = val_df['text'].tolist()\n",
    "val_labels = val_df['label'].tolist()\n",
    "\n",
    "#Define storage\n",
    "all_probabilities = []\n",
    "all_labels = []\n",
    "\n",
    "#Step 1: Tokenization and sorting by token length\n",
    "tokenized_inputs = []\n",
    "for text, label in zip(val_texts, val_labels):\n",
    "    test_str = prompt.format(text, \"\")\n",
    "    tokenized_input = tokenizer(test_str, return_tensors=\"pt\", add_special_tokens=False)\n",
    "    tokenized_inputs.append((tokenized_input, test_str, label))\n",
    "\n",
    "#Sort by tokenized length\n",
    "tokenized_inputs.sort(key=lambda x: x[0]['input_ids'].shape[1])\n",
    "\n",
    "#Step 2: Group by tokenized length\n",
    "grouped_inputs = defaultdict(list)\n",
    "for tokenized_input, test_str, label in tokenized_inputs:\n",
    "    length = tokenized_input['input_ids'].shape[1]\n",
    "    grouped_inputs[length].append((tokenized_input, test_str, label))\n",
    "\n",
    "#Step 3: Process batches\n",
    "batch_size = 64\n",
    "\n",
    "for length, group in tqdm(grouped_inputs.items()):\n",
    "    for i in range(0, len(group), batch_size):\n",
    "        batch = group[i:i + batch_size]\n",
    "        batch_inputs = [item[0] for item in batch]\n",
    "        batch_labels = [item[2] for item in batch]\n",
    "\n",
    "        #Concatenate batch inputs\n",
    "        input_ids = torch.cat([item['input_ids'] for item in batch_inputs], dim=0).to(\"cuda\")\n",
    "        attention_mask = torch.cat([item['attention_mask'] for item in batch_inputs], dim=0).to(\"cuda\")\n",
    "\n",
    "        #Forward pass\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        #Extract logits for classification\n",
    "        logits = outputs.logits[:, -1, :2]\n",
    "        probabilities = F.softmax(logits, dim=-1)[:, 1].cpu().numpy()  #Probability of class 1\n",
    "\n",
    "        #Store results\n",
    "        all_probabilities.extend(probabilities)\n",
    "        all_labels.extend(batch_labels)\n",
    "\n",
    "#Step 4: Compute ROC curve and AUC\n",
    "fpr, tpr, thresholds = roc_curve(all_labels, all_probabilities)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "#Save ROC data\n",
    "np.savetxt(os.path.join(output_dir, \"fpr_Qwen3_14B.txt\"), fpr)\n",
    "np.savetxt(os.path.join(output_dir, \"tpr_Qwen3_14B.txt\"), tpr)\n",
    "np.savetxt(os.path.join(output_dir, \"thresholds_Qwen3_14B.txt\"), thresholds)\n",
    "with open(os.path.join(output_dir, \"auc_Qwen3_14B.txt\"), \"w\") as f:\n",
    "    f.write(f\"AUC: {roc_auc:.4f}\\n\")\n",
    "\n",
    "#Step 5: Find optimal threshold\n",
    "optimal_idx = (tpr - fpr).argmax()\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "print(f\"Optimal Threshold: {optimal_threshold:.4f}\")\n",
    "\n",
    "#Step 6: Convert probabilities to binary predictions\n",
    "all_outputs = (all_probabilities >= optimal_threshold).astype(int)\n",
    "\n",
    "#Step 7: Compute evaluation metrics\n",
    "cm = confusion_matrix(all_labels, all_outputs)\n",
    "accuracy = accuracy_score(all_labels, all_outputs)\n",
    "precision = precision_score(all_labels, all_outputs)\n",
    "recall = recall_score(all_labels, all_outputs)\n",
    "f1 = f1_score(all_labels, all_outputs)\n",
    "\n",
    "#Step 8: Save all metrics + confusion matrix to a single file\n",
    "metrics_file = os.path.join(output_dir, \"metrics_Qwen3_14B.txt\")\n",
    "with open(metrics_file, \"w\") as f:\n",
    "    f.write(\"===== Model Evaluation Metrics =====\\n\")\n",
    "    f.write(f\"Accuracy: {accuracy:.4f}\\n\")\n",
    "    f.write(f\"Precision: {precision:.4f}\\n\")\n",
    "    f.write(f\"Recall: {recall:.4f}\\n\")\n",
    "    f.write(f\"F1-Score: {f1:.4f}\\n\")\n",
    "    f.write(f\"AUC: {roc_auc:.4f}\\n\")\n",
    "    \n",
    "    f.write(\"\\n===== Confusion Matrix =====\\n\")\n",
    "    np.savetxt(f, cm, fmt=\"%d\")\n",
    "\n",
    "print(f\"\\nMetrics saved to: {metrics_file}\")\n",
    "\n",
    "#Step 9: Save confusion matrix separately\n",
    "np.savetxt(os.path.join(output_dir, \"confusion_matrix_Qwen3_14B.txt\"), cm, fmt='%d')\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)\n",
    "print(\"\\nEvaluation Metrics:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "print(f\"AUC: {roc_auc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
